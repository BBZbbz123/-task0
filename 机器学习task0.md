### 1. 监督学习与无监督学习的区别
- **监督学习**  
  - 使用**带标签**的数据进行训练（每个样本都有输入和对应的输出）。
  - 目标：学习输入和输出之间的映射关系，进行**分类**或**回归**任务。  
  - 示例：房价预测（回归）、垃圾邮件识别（分类）。  
  - 常用算法：线性回归、逻辑回归、支持向量机（SVM）、神经网络等。

- **无监督学习**  
  - 使用**无标签**的数据，只对输入数据进行建模，发现数据的潜在结构或分布。  
  - 目标：**聚类**、降维、异常检测等。  
  - 示例：客户分群、主成分分析（PCA）进行降维。  
  - 常用算法：K-means、DBSCAN、PCA、自编码器等。

---

### 2. 机器学习和深度学习的区别
- **机器学习（ML）**  
  - 是**传统的算法**模型，可以用于处理结构化数据，通常需要人为提取特征。
  - 示例算法：决策树、支持向量机、KNN等。
  - **适合数据量小**的任务。

- **深度学习（DL）**  
  - 机器学习的一个分支，主要依赖**多层神经网络**处理数据。
  - 特点：不需要人为设计特征，模型**自动学习**特征。  
  - 适用于**大规模数据和复杂任务**，如图像识别、自然语言处理。
  - 典型模型：卷积神经网络（CNN）、循环神经网络（RNN）、Transformer等。

---

### 3. 偏导数、链式法则、梯度、矩阵等数学概念在机器学习中的作用
- **偏导数**：  
  - 用于描述函数对多个变量中的一个变量的变化率。  
  - 在神经网络中，用于计算**损失函数对每一层参数的偏导**。

- **链式法则**：  
  - 当一个函数由多个嵌套函数组成时，用链式法则求导可以**逐层更新参数**。  
  - 在反向传播（Backpropagation）中用于计算梯度。

- **梯度**：  
  - 是向量形式的导数，表示函数的变化方向和速率。  
  - 在梯度下降中使用，**沿梯度的反方向**调整参数，减少损失。

- **矩阵**：  
  - 神经网络中的输入、权重和激活都用矩阵表示。  
  - 矩阵乘法用于**高效计算每一层的输出**。

---

### 4. 常见的激活函数
- **Sigmoid**：  
  \[ \sigma(x) = \frac{1}{1 + e^{-x}} \]  
  - 输出范围：0到1，适合概率输出。
  - 缺点：梯度消失。

- **Tanh**：  
  \[ \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \]  
  - 输出范围：-1到1，相比Sigmoid更适合有负值的数据。

- **ReLU（Rectified Linear Unit）**：  
  \[ f(x) = \max(0, x) \]  
  - 计算简单，收敛快。
  - 缺点：可能出现“神经元死亡”（输出一直为0）。

- **Leaky ReLU**：  
  \[ f(x) = \max(\alpha x, x) \quad (\alpha > 0) \]  
  - 改进ReLU，允许小负斜率，缓解“神经元死亡”问题。

- **Softmax**：  
  \[ \text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}} \]  
  - 将输出转换为概率分布，常用于分类任务的最后一层。

---

### 5. 神经网络的基本结构
- **输入层**：  
  - 接收原始数据输入（如图像像素、文本向量）。

- **隐藏层**：  
  - 各层由若干神经元组成，每个神经元执行**线性变换+激活函数**。  
  - 隐藏层数较多时，构成**深度神经网络**。

- **输出层**：  
  - 输出模型预测结果，根据任务不同可能是一个标量（回归）或分类概率（Softmax）。

- **连接权重与偏置**：  
  - 每条连接有一个权重，偏置用于调节神经元的激活。

- **损失函数**：  
  - 衡量模型输出与真实标签之间的误差，如均方误差（MSE）、交叉熵。

- **优化器**：  
  - 如**梯度下降法**或其变体（Adam、RMSProp），用于更新网络参数。

---

### 6. 机器学习中的数据处理
- **数据清洗**：
  - 处理缺失值、重复数据、异常值。  
  - 示例：用均值填充缺失值，删除重复数据。

- **数据标准化/归一化**：
  - 标准化：将数据转为**标准正态分布**（均值0，方差1）。
  - 归一化：将数据缩放到**固定区间**（如0到1）。

- **特征工程**：
  - 提取有用特征，如时间戳转换为季节、星期等特征。
  - 通过**特征选择**降低维度（如用Lasso回归筛选特征）。

- **数据集划分**：
  - 将数据集分为训练集、验证集和测试集，通常比例是**8:1:1**。

- **数据增强**：
  - 特别在图像处理任务中使用，如旋转、缩放、翻转来生成更多样本。

- **处理类别不平衡**：
  - 使用**过采样**（SMOTE）或**欠采样**方法平衡类别。

- **交叉验证**：
  - 将数据划分为若干个子集，循环训练和验证，提高模型的泛化能力。