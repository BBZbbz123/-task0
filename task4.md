**学习笔记：《A Watermark for Large Language Models》**

## 1.论文概述

这篇论文研究了一种为大语言模型生成的文本嵌入“水印”的技术。水印是一种隐蔽标记，可以通过算法检测但不会影响文本的可读性。其目的主要是防止模型滥用，如识别盗版模型生成的内容或溯源模型输出。

论文提出了**两种水印算法**：**Hard Watermark（硬水印）** 和 **Soft Watermark（软水印）**，并讨论了它们在生成、检测及应对攻击中的表现。

## 2. Logits 是什么？
Logits 是模型在最后一层输出的非标准化分数。这些分数代表了每个候选输出（如词汇表中的单词）的“相对倾向”，但尚未转换为概率。模型生成每个输出词时，先计算 logits，然后通过概率函数（通常是 softmax）将其转换为一个概率分布。可以把 logits 理解为对模型认为每个词的“合适程度”的初步估计。

## 3. Softmax 函数是什么？

Softmax 是一种函数，用来将 logits 转换为概率分布。它通过指数化每个 logit，并将这些值标准化为 0 到 1 之间的概率，这些概率的总和为 1。公式如下：

```latex
\[
p_i = \frac{e^{l_i}}{\sum_j e^{l_j}}
\]

```

其中 \(p_i\) 是第 \(i\) 个词的概率，\(l_i\) 是对应的 logit。

这一过程确保了所有词的概率之和为 1，适合用于分类任务和语言模型的词生成。

## 4. Attention 机制

Attention 是神经网络的一种方法，允许模型根据输入序列中不同部分的重要性分配“注意力”。这在长序列处理中非常关键，尤其在处理自然语言时可以帮助模型在生成某个词时考虑远距离的上下文。Attention 机制中的核心思想是为每个输入元素计算一个权重，然后根据这些权重加权求和，得到更具代表性的输出。

## 5. Transformer
Transformer 是一种以 Attention 机制为基础的神经网络架构，主要用于自然语言处理任务。它去除了传统 RNN 依赖于时间步的顺序处理方式，使用自注意力（Self-Attention）机制来并行处理整个输入序列。Transformer 模型包括编码器和解码器部分，是现今大多数大型语言模型（如 GPT、BERT 等）的基础。

## 6. LLM 的基本架构及自回归模型
大型语言模型（LLMs）通常是自回归模型，这意味着它们通过逐步预测下一个词来生成文本。每次生成时，模型根据已经生成的部分作为上下文，预测下一个词的概率分布。自回归生成过程使得模型能够根据前面的输出不断调整后续的预测，保持语义连贯性。

在 **自回归模型** 中，生成序列的过程如下：
1. 给定初始输入或提示词，模型根据提示生成第一个词。
2. 接着，模型将第一个词作为输入的一部分，用来预测第二个词。
3. 这一过程重复，直到生成完整的句子或文本。

## 7.两种水印算法的原理与差异
#### 1. Hard Watermark（硬水印）
- **核心思路**：严格限制模型生成某些词汇（称为“红名单”），并鼓励使用另一部分词汇（“绿名单”）。
- **工作机制**：
  1. 在生成每个词时，使用伪随机数生成器将词汇表随机分为绿名单和红名单。
  2. 只允许从绿名单中选择词汇来生成输出。
  
- **优点**：水印的检测较为简单，通过统计学方法（如z检验）可以快速识别。
- **缺点**：如果某段文本中的高频词集中在红名单，则可能影响生成质量。

#### 2. Soft Watermark（软水印）
- **核心思路**：对绿名单中的词施加微弱的权重偏好，但不完全禁止红名单词汇。
- **工作机制**：
  1. 在模型输出的概率分布（logits）上，给绿名单词汇增加一个常量权重 δ。
  2. 使用软化后的分布进行采样，使生成的文本更偏向绿名单但不显著影响质量。
- **优点**：更灵活，不会破坏文本质量，尤其适用于自然语言生成中的高熵场景。
- **缺点**：检测相对复杂，需要更精细的统计分析。

---

## 8.红名单与绿名单

在论文《A Watermark for Large Language Models》中，“红名单”（Red List）和“绿名单”（Green List）是指在文本生成过程中对词汇表的随机划分。这些名单的作用是限制或引导模型在生成文本时的词汇选择，从而实现水印的嵌入。

#### **绿名单（Green List）**
- **定义**：在模型生成每个词时，使用伪随机数生成器将词汇表的一部分划分为绿名单。 
- **作用**：水印算法会“鼓励”模型更多地选择绿名单中的词汇，以便在生成的文本中嵌入水印信息。
- **软水印中的操作**：对绿名单词汇的概率分布（logit）增加一个常数偏移量（δ），从而微调模型的输出，使得这些词汇更容易被选择。

#### **红名单（Red List）**
- **定义**：同样是通过伪随机数生成器划分出的另一部分词汇表。
- **作用**：红名单中的词汇在硬水印算法中会被严格禁止使用，而在软水印算法中则不会完全禁止，只是概率权重较低。
- **影响**：红名单的设置可能会限制某些高频词的使用。例如，如果“Barack”出现在句子中，模型会倾向于输出“Obama”，但“Obama”可能被红名单屏蔽掉，导致输出质量下降。

## 9.攻击方式

1. 论文《A Watermark for Large Language Models》中描述了多种针对水印的攻击方式。以下是主要的攻击方式及其背后的逻辑思考：

   ---

   1. #### **词汇替换攻击（Token Replacement Attack）**

   - **方法**：攻击者修改水印文本中的部分词汇，以降低水印检测的显著性。
   - **效果分析**：
     - 在硬水印算法中，如果能替换足够多的绿名单词汇为红名单词汇，水印会变得不明显。
     - 然而，论文指出**需要修改至少四分之一的词汇**才能有效去除硬水印，这可能严重影响文本的可读性和流畅度。

   ---

   #### 2. **重排攻击（Reordering Attack）**
   - **方法**：通过打乱词语的顺序，使水印的统计特征减弱。
   - **效果分析**：  
     - 此攻击在硬水印的限制条件下较为有效，因为硬水印依赖于文本序列中词汇的特定分布。
     - 然而，软水印在设计上对这种重排更加耐受，因其主要依赖于概率偏移而非严格的词汇选择。

   ---

   ### 3. **低熵文本攻击（Low-Entropy Attack）**
   - **方法**：针对模型生成的低熵（即词汇选择高度确定）文本进行攻击。
   - **效果分析**：  
     - 在低熵场景下，例如“Barack”后面必定生成“Obama”时，模型几乎没有选择余地，绿名单和红名单的划分就变得无效。
     - 因此，软水印算法会在低熵情况下自动降低水印强度，使其对这些情境的适应性更强。

   ---

   ### 4. **信息泄露攻击（Exposure Attack）**
   - **方法**：若攻击者能掌握水印算法的详细逻辑和规则，则可以更有针对性地修改文本来删除水印。
   - **效果分析**：  
     - 论文提到，**水印算法的保密性**至关重要。若算法公开，攻击者能精准识别绿名单和红名单，极大削弱水印的有效性。

   ---

   ### 5. **随机扰动攻击（Random Perturbation Attack）**
   - **方法**：随机修改文本中的词汇，期望降低水印检测的可能性。
   - **效果分析**：
     - 如果攻击者不了解具体的水印算法，这种随机扰动攻击的效果有限。论文指出，随机替换词汇的情况下，替换词汇有50%的概率仍落在绿名单中，因此水印仍然可能被检测到。

   

## 10.攻击方式有效的原因

这些攻击方式之所以有效，是因为它们利用了水印算法的**统计性特征**以及大语言模型在生成文本时的**局限性**。以下分析了每种攻击方式的有效原因：

###  **1.词汇替换攻击的有效性**

- **原因**：
  - 水印依赖于特定词汇的使用频率或选择倾向。攻击者通过替换水印嵌入的“绿名单”词汇，改变统计特征，从而削弱水印检测。
  - 在**硬水印**中，如果足够多的绿名单词汇被替换为红名单词汇，水印的显著性会大幅降低。
  - 但替换需要在不影响语义和流畅度的情况下进行，否则会暴露攻击痕迹，因此此方法的应用需要**高词汇替换比例**来达到有效效果。

---

###  **2.重排攻击的有效性**
- **原因**：
  - 语言模型的输出有**序列依赖**，即词汇的顺序对水印检测至关重要。硬水印特别依赖这些顺序特性。
  - 当词汇的顺序被打乱时，即便词汇本身保持不变，统计检测也会失效或显著降低检测率。因此，重排攻击对**硬水印**非常有效。
  - 但由于**软水印依赖概率偏好**而非严格的词汇选择和顺序，它在这方面具有更好的鲁棒性。

---

###  **3.低熵文本攻击的有效性**
- **原因**：
  - 在一些自然语言场景中，模型生成的词汇序列具有高度确定性（即低熵）。例如，在生成人名时，“Barack”后面几乎总是“Obama”。
  - 由于低熵环境下模型的选择空间非常小，水印算法的**绿名单与红名单划分无法有效发挥作用**，使得水印的嵌入和检测变得困难。因此，这类场景是水印算法的天然弱点。

---

###  **4.信息泄露攻击的有效性**
- **原因**：
  - 水印的有效性通常依赖于**算法的保密性**（即攻击者无法知道词汇表的具体划分）。一旦攻击者获得了绿名单和红名单的划分信息，他们可以有针对性地替换词汇或重排句子，削弱水印。
  - 这种攻击展示了水印方案在实际部署中需要兼顾**算法的透明度和鲁棒性**之间的平衡。

###  **5.随机扰动攻击的有效性**

- **原因**：
  - 随机扰动攻击（即随机替换或插入词汇）利用了模型输出的**统计随机性**。在某些情况下，尽管替换的词汇可能仍然属于绿名单，但在足够多次扰动后，统计特征会发生变化，影响水印检测。
  - **硬水印**容易受到此类攻击的影响，因为它依赖于严格的词汇限制；而**软水印**由于允许一定的随机性，因此具有更好的抗扰性。

